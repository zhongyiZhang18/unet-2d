{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from modelapi import model\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        io.imsave(os.path.join(save_path,\"predict.png\"),img)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: /contrib_src/sample_data/0.png\n",
      "'single'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8a1af360a344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nInput:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" Output \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Type:  \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'output'"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "samples = model.get_samples()\n",
    "if len(samples[\"files\"]) > 0:\n",
    "    inputFile = samples[\"folder\"] + \"/\" + samples[\"files\"][0]\n",
    "    print (\"\\nInput:\", inputFile)\n",
    "    result = model.predict(inputFile)\n",
    "    for i, output in enumerate(result[\"output\"]):\n",
    "        print(\"\\n\" + result[\"model\"][\"name\"] + \" Output \" + str(i) + \":\")\n",
    "        print(\"  Type:  \" + output[\"type\"])\n",
    "        print(\"  Name:  \" + output[\"name\"])\n",
    "        print(\"  Shape: \" + str(output[\"shape\"]))\n",
    "        print(\"  Prediction (top 5):\")\n",
    "        sorted_list = sorted(output[\"prediction\"], key=itemgetter('probability'), reverse = True)\n",
    "        for i, element in enumerate(sorted_list):\n",
    "            if i > 4: break\n",
    "            print (\"   \", element[\"probability\"], element[\"label\"])\n",
    "else:\n",
    "    model_name = model.get_config()[\"meta\"][\"name\"]\n",
    "    print(model_name + \" does not provide any sample data, please try your own data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input: /contrib_src/sample_data/0.png\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ModelHubAPI' object has no attribute 'infer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1f05b08d3c5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minputFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"folder\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"files\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nInput:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelHubAPI' object has no attribute 'infer'"
     ]
    }
   ],
   "source": [
    "samples = model.get_samples()\n",
    "inputFile = samples[\"folder\"] + \"/\" + samples[\"files\"][0]\n",
    "print (\"\\nInput:\", inputFile)\n",
    "result = model.infer(inputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on ModelHubAPI in module modelhubapi.pythonapi object:\n",
      "\n",
      "class ModelHubAPI(builtins.object)\n",
      " |  Generic interface to access a model.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, model, contrib_src_dir)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns:\n",
      " |          dict: Model configuration.\n",
      " |  \n",
      " |  get_legal(self)\n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              All of modelhub's, the model's, and the sample data's\n",
      " |              legal documents as dictionary. If one (or more) of the legal\n",
      " |              files don't exist, the error  will be logged with the\n",
      " |              corresponding key. Dictionary keys are:\n",
      " |      \n",
      " |              - modelhub_license\n",
      " |              - modelhub_acknowledgements\n",
      " |              - model_license\n",
      " |              - sample_data_license\n",
      " |  \n",
      " |  get_model_io(self)\n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              The model's input/output sizes and types as dictionary.\n",
      " |              Convenience function, as this is a subset of what\n",
      " |              :func:`~get_config` returns\n",
      " |  \n",
      " |  get_samples(self)\n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              Folder and file names of sample data bundled with this model.\n",
      " |              The diconary key \"folder\" holds the absolute path to the\n",
      " |              sample data folder in the model container. The key \"files\"\n",
      " |              contains a list of all file names in that folder. Join these\n",
      " |              together to get the full path to the sample files.\n",
      " |  \n",
      " |  predict(self, input_file_path, numpyToFile=True, url_root='')\n",
      " |      Preforms the model's inference on the given input.\n",
      " |      \n",
      " |      Args:\n",
      " |          input_file_path (str or dict): Path to input file to run inference on.\n",
      " |              Either a direct input file or a json containing paths to all\n",
      " |              input files needed for the model to predict. The appropriate\n",
      " |              structure for the json can be found in the documentation.\n",
      " |              If used directly, you can also pass a dict with the keys.\n",
      " |          numpyToFile (bool): Only effective if prediction is a numpy array.\n",
      " |              Indicates if numpy outputs should be saved and a path to it is\n",
      " |              returned. If false, a json-serializable list representation of\n",
      " |              the numpy array is returned instead. List representations is\n",
      " |              very slow with large numpy arrays.\n",
      " |          url_root (str): Url root added by the rest api.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict, list, or numpy array:\n",
      " |              Prediction result on input data. Return type/foramt as\n",
      " |              specified in the model configuration (see :func:`~get_model_io`).\n",
      " |              In case of an error, returns a dictionary\n",
      " |              with error info.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelhubapi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-6a9c36b5a418>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelhubapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'modelhubapi' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
